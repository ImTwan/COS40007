{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djA6PWIgTEHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5de0b1-af02-4136-e7d8-1de853c3a391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass this step if you have already unzip the tar.gz files\n",
        "import tarfile\n",
        "\n",
        "# Define the paths to your .tar.gz files\n",
        "file_path_images = '/content/drive/MyDrive/Colab Notebooks/dataset/images.tar.gz'\n",
        "file_path_bounding_boxes = '/content/drive/MyDrive/Colab Notebooks/dataset/bounding_boxes.tar.gz'\n",
        "\n",
        "# Extract the contents of the images.tar.gz file\n",
        "with tarfile.open(file_path_images, 'r:gz') as tar:\n",
        "    tar.extractall(path='/content/drive/MyDrive/Colab Notebooks/dataset/')\n",
        "\n",
        "# Extract the contents of the bounding_boxes.tar.gz file\n",
        "with tarfile.open(file_path_bounding_boxes, 'r:gz') as tar:\n",
        "    tar.extractall(path='/content/drive/MyDrive/Colab Notebooks/dataset/')\n",
        "\n",
        "print(\"Extraction complete for both files!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZlZB-euidQJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8941accd-1e1e-4cb7-c7be-b45f7a941e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete for both files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a function to convert given annotation format in training labels to YOLO annotation\n",
        "format (The code for Step 1)**"
      ],
      "metadata": {
        "id": "a-UevWTJfNxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ALKkIM0zfQ0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = '/content/drive/MyDrive/Colab Notebooks/dataset/Bounding_boxes/train_labels.csv'\n",
        "test_csv = '/content/drive/MyDrive/Colab Notebooks/dataset/Bounding_boxes/test_labels.csv'\n",
        "\n",
        "\n",
        "train_img = '/content/drive/MyDrive/Colab Notebooks/dataset/images/train'\n",
        "test_img = '/content/drive/MyDrive/Colab Notebooks/dataset/images/test'\n",
        "\n",
        "train_labels = '/content/drive/MyDrive/Colab Notebooks/dataset/labels/train'\n",
        "test_labels = '/content/drive/MyDrive/Colab Notebooks/dataset/labels/test'\n",
        "\n",
        "class_mapping = {'Graffiti': 0}"
      ],
      "metadata": {
        "id": "Pn-PBtkmgkdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_annotation_convert(csv_file, images_dir, output_dir, class_mapping):\n",
        "    df = pd.read_csv(csv_file)  # Load the CSV containing annotations\n",
        "    grouped_annotations = df.groupby('filename')  # Group annotations by image filename\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Iterate through each image and its corresponding annotations\n",
        "    for image_name, image_annotations in tqdm(grouped_annotations, desc=f'Processing annotations for {csv_file}'):\n",
        "        image_path = os.path.join(images_dir, image_name)  # Get the full path to the image\n",
        "        if not os.path.exists(image_path):  # Skip if the image doesn't exist\n",
        "            continue\n",
        "\n",
        "        # Get the image dimensions (width and height)\n",
        "        image_width = image_annotations.iloc[0]['width']\n",
        "        image_height = image_annotations.iloc[0]['height']\n",
        "\n",
        "        yolo_annotations = []  # List to store the YOLO annotations\n",
        "\n",
        "        # Loop through each row in the group of annotations for this image\n",
        "        for _, row in image_annotations.iterrows():\n",
        "            class_id = class_mapping[row['class']]  # Get the class ID from the mapping\n",
        "            xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
        "\n",
        "            # Calculate normalized bounding box parameters\n",
        "            x_center = ((xmin + xmax) / 2) / image_width\n",
        "            y_center = ((ymin + ymax) / 2) / image_height\n",
        "            bbox_width = (xmax - xmin) / image_width\n",
        "            bbox_height = (ymax - ymin) / image_height\n",
        "\n",
        "            # Format the annotation in YOLO format\n",
        "            yolo_annotations.append(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\")\n",
        "\n",
        "        # Write the annotations to a text file\n",
        "        txt_filename = os.path.splitext(image_name)[0] + '.txt'  # Output text file name\n",
        "        with open(os.path.join(output_dir, txt_filename), 'w') as file:\n",
        "            for annotation in yolo_annotations:\n",
        "                file.write(annotation + '\\n')"
      ],
      "metadata": {
        "id": "v1gf48OOiDTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_annotation_convert(train_csv, train_img, train_labels, class_mapping)\n",
        "yolo_annotation_convert(test_csv, test_img, test_labels, class_mapping)"
      ],
      "metadata": {
        "id": "dcYAdb30kMtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb8d838-2693-4053-8689-511181d93349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing annotations for /content/drive/MyDrive/Colab Notebooks/dataset/Bounding_boxes/train_labels.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 813/813 [00:05<00:00, 144.07it/s]\n",
            "Processing annotations for /content/drive/MyDrive/Colab Notebooks/dataset/Bounding_boxes/test_labels.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:01<00:00, 111.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count the files\n",
        "def files_count(dir_path):\n",
        "  if not os.path.exists(dir_path):\n",
        "    return 0\n",
        "  return len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
        "\n",
        "train_img_count = files_count(train_img)\n",
        "train_labels_count = files_count(train_labels)\n",
        "\n",
        "test_img_count = files_count(test_img)\n",
        "test_labels_count = files_count(test_labels)\n",
        "\n",
        "print(f\"Number of files in train_img: {train_img_count}\")\n",
        "print(f\"Number of files in train_labels: {train_labels_count}\")\n",
        "print(f\"Number of files in test_img: {test_img_count}\")\n",
        "print(f\"Number of files in test_labels: {test_labels_count}\")"
      ],
      "metadata": {
        "id": "A9CmB1zg7KKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1574f90e-a0e3-4ef4-a23f-74f1d3af2f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in train_img: 813\n",
            "Number of files in train_labels: 813\n",
            "Number of files in test_img: 209\n",
            "Number of files in test_labels: 209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and create a YOLO model by randomly taking 400 images from train data which can\n",
        "detect graffiti in the image**"
      ],
      "metadata": {
        "id": "yJsYy-CNpENf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "XOZAVMBd1FG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new folders for the selected images and their corresponding annotations\n",
        "selected_train_img_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/images/selected_train'\n",
        "selected_train_labels_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train'\n",
        "selected_test_img_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/images/selected_test'\n",
        "selected_test_labels_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test'\n"
      ],
      "metadata": {
        "id": "_7smK2pj4gWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_selecting(source_directory, destination_directory, num_img, img_used=set()):\n",
        "    img = [file for file in os.listdir(source_directory) if (file.endswith('.jpg') or file.endswith('.JPG')) and file not in img_used]\n",
        "    img_selected = random.sample(img, min(num_img, len(img)))\n",
        "    img_used.update(img_selected)\n",
        "\n",
        "    if not os.path.exists(destination_directory):\n",
        "        os.makedirs(destination_directory)\n",
        "\n",
        "    # Clear existing files in destination directory\n",
        "    for file in os.listdir(destination_directory):\n",
        "        file_path = os.path.join(destination_directory, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "\n",
        "    for i in img_selected:\n",
        "        shutil.copy(os.path.join(source_directory, i), os.path.join(destination_directory, i))\n",
        "    return img_used\n"
      ],
      "metadata": {
        "id": "z5jU1W_W5Kxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anno_copy(img_directory, label_destination_directory, label_source_directory):\n",
        "    if not os.path.exists(label_destination_directory):\n",
        "        os.makedirs(label_destination_directory)\n",
        "\n",
        "    # Clear existing files in destination directory\n",
        "    for file in os.listdir(label_destination_directory):\n",
        "        file_path = os.path.join(label_destination_directory, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "\n",
        "    for image_file in os.listdir(img_directory):\n",
        "        if image_file.endswith('.jpg') or image_file.endswith('.JPG'):\n",
        "            root_name = os.path.splitext(image_file)[0]\n",
        "            annotation_file = root_name + '.txt'\n",
        "            source_label_path = os.path.join(label_source_directory, annotation_file)\n",
        "            destination_label_path = os.path.join(label_destination_directory, annotation_file)\n",
        "            if os.path.exists(source_label_path):\n",
        "                shutil.copy(source_label_path, destination_label_path)\n"
      ],
      "metadata": {
        "id": "4of977rLDxGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 400 images from the training set\n",
        "random.seed(42)\n",
        "selected_train_img = set()\n",
        "selected_train_img = image_selecting(train_img, selected_train_img_dir, 400, selected_train_img)\n",
        "anno_copy(train_img, selected_train_labels_dir, train_labels)\n",
        "\n",
        "# Select 40 images from the test set\n",
        "random.seed(42)\n",
        "selected_test_img = set()\n",
        "selected_test_img = image_selecting(test_img, selected_test_img_dir, 40, selected_test_img)\n",
        "anno_copy(test_img, selected_test_labels_dir, test_labels)"
      ],
      "metadata": {
        "id": "bkMVqp2b9KLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "iPh-uNI9ze-5",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f096d15-eacb-49db-9e0f-6416aa7ad010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.78-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.78-py3-none-any.whl (921 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m921.5/921.5 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.78 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train YOLO model with Ultralytics**"
      ],
      "metadata": {
        "id": "VOPzYYm_o_Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import yaml"
      ],
      "metadata": {
        "id": "QAufy_Sk0YgW",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7febeaa7-b5fd-44d0-d093-215dd9c59a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create YAML file\n",
        "# Define the paths for the images\n",
        "train_img_path = os.path.abspath(selected_train_img_dir)\n",
        "val_img_path = os.path.abspath(selected_test_img_dir)\n",
        "\n",
        "# Define the YAML file path\n",
        "yaml_file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/graffiti.yaml'\n",
        "\n",
        "\n",
        "# Create the data dictionary for the YAML file\n",
        "data_dict = {\n",
        "    'train': train_img_path,\n",
        "    'val': val_img_path,\n",
        "    'nc': 1,\n",
        "    'names': ['Graffiti'],\n",
        "\n",
        "}\n",
        "\n",
        "# Write the dictionary to the YAML file\n",
        "with open(yaml_file_path, 'w') as file:\n",
        "    yaml.dump(data_dict, file, indent=2)\n",
        "\n",
        "print(\"YAML file created and saved at:\", yaml_file_path)\n"
      ],
      "metadata": {
        "id": "PqvDMW-PY26J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02e34ae-0d67-4d84-cbe1-c1fb98f78c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML file created and saved at: /content/drive/MyDrive/Colab Notebooks/dataset/graffiti.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_path = '/content/drive/MyDrive/Colab Notebooks/dataset/graffiti.yaml'\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "#Train model\n",
        "train = model.train(data = yaml_path, epochs = 5, imgsz=640, batch=16, name='graffiti_detection')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TgbyILyGgkSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd45668-6d10-44d5-f7fb-68a0a152ca5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 266MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/Colab Notebooks/dataset/graffiti.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=graffiti_detection, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/graffiti_detection\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 89.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/graffiti_detection', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train... 400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:03<00:00, 130.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 105.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test.cache\n",
            "Plotting labels to runs/detect/graffiti_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/graffiti_detection\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      2.32G      1.505      3.001       1.43         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:10<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40        118     0.0065      0.661      0.145     0.0728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5      2.22G       1.52      2.281      1.382         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  3.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40        118      0.335      0.111      0.125     0.0574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5      2.27G      1.483      2.212      1.407         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:10<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40        118      0.316      0.136      0.134     0.0523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5      2.22G      1.461      2.018      1.378         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40        118      0.401      0.254      0.251      0.117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5      2.23G      1.342      1.856      1.303         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40        118       0.48      0.352      0.356      0.215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5 epochs completed in 0.018 hours.\n",
            "Optimizer stripped from runs/detect/graffiti_detection/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/graffiti_detection/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/graffiti_detection/weights/best.pt...\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40        118      0.478      0.347      0.355      0.214\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/graffiti_detection\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.ops import box_iou\n",
        "from PIL import Image\n",
        "import csv"
      ],
      "metadata": {
        "id": "AVJsVTwIjPVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_bb_IoU(pred_bboxeses, gt_bboxeses):\n",
        "    # Convert boxes to tensors\n",
        "    pred_bboxes = torch.tensor(pred_bboxeses)  # Corrected variable name\n",
        "    gt_bboxes = torch.tensor(gt_bboxeses)\n",
        "\n",
        "    # Calculate the (x1, y1) coordinates of the intersection rectangle\n",
        "    inter_x1 = torch.max(pred_bboxes[0], gt_bboxes[0])\n",
        "    inter_y1 = torch.max(pred_bboxes[1], gt_bboxes[1])\n",
        "\n",
        "    # Calculate the (x2, y2) coordinates of the intersection rectangle\n",
        "    inter_x2 = torch.min(pred_bboxes[2], gt_bboxes[2])\n",
        "    inter_y2 = torch.min(pred_bboxes[3], gt_bboxes[3])\n",
        "\n",
        "    # Calculate the width and height of the intersection rectangle\n",
        "    inter_width = (inter_x2 - inter_x1).clamp(min=0)\n",
        "    inter_height = (inter_y2 - inter_y1).clamp(min=0)\n",
        "\n",
        "    # Calculate the area of the intersection rectangle\n",
        "    inter_area = inter_width * inter_height\n",
        "\n",
        "    # Calculate the area of the predicted and true bounding boxes\n",
        "    pred_area = (pred_bboxes[2] - pred_bboxes[0]) * (pred_bboxes[3] - pred_bboxes[1])\n",
        "    gt_area = (gt_bboxes[2] - gt_bboxes[0]) * (gt_bboxes[3] - gt_bboxes[1])\n",
        "\n",
        "    # Calculate the area of the union of the two bounding boxes\n",
        "    union_area = pred_area + gt_area - inter_area\n",
        "\n",
        "    # Avoid division by zero if union area is 0\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate the IoU score\n",
        "    iou = inter_area / union_area\n",
        "    return iou.item()"
      ],
      "metadata": {
        "id": "qZcmxRBiqdTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluation(model, images_dir, labels_dir, output_img_dir = None, IoU_threshold=0.5):\n",
        "    eva_results = []  # Initialize a list to collect evaluation data for each image\n",
        "\n",
        "    # Create a list of image files with '.jpg' extension in the images directory\n",
        "    img_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg'))]\n",
        "\n",
        "    # Iterate over each image file and show a progress bar with tqdm\n",
        "    for img_file in tqdm(img_files, desc=\"Evaluating.....\"):\n",
        "        img_path = os.path.join(images_dir, img_file)\n",
        "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "\n",
        "        ground_truth_boxes = []\n",
        "\n",
        "        # If a corresponding label file is found, read the ground truth bounding boxes\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    components = line.strip().split()\n",
        "                    # Ensure the line is properly formatted (class, x_center, y_center, width, height)\n",
        "                    if len(components) != 5:\n",
        "                        continue\n",
        "                    # Convert the bounding box details and class into appropriate float values\n",
        "                    cls, x_center, y_center, width, height = map(float, components)\n",
        "                    img = Image.open(img_path)\n",
        "                    img_width, img_height = img.size\n",
        "                    # Calculate pixel coordinates from normalized bounding box values\n",
        "                    x1 = (x_center - width / 2) * img_width\n",
        "                    y1 = (y_center - height / 2) * img_height\n",
        "                    x2 = (x_center + width / 2) * img_width\n",
        "                    y2 = (y_center + height / 2) * img_height\n",
        "                    # Add the true bounding box to the list of ground truth\n",
        "                    ground_truth_boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "        # Get predictions for the current image from the model\n",
        "        predictions = model.predict(img_path, conf = IoU_threshold, verbose = False)\n",
        "        predicted_boxes = []\n",
        "        confs = []\n",
        "\n",
        "        # Loop through model predictions to extract bounding boxes and their associated conf scores\n",
        "        for pred in predictions:\n",
        "            if len(pred.boxes) > 0:\n",
        "                predicted_boxes.append(pred.boxes.xyxy[0].tolist())  # Extract box coordinates\n",
        "                confs.append(pred.boxes.conf[0].item())  # Extract conf score\n",
        "\n",
        "        # If both predicted boxes and ground truth boxes exist, evaluate the Intersection over Union (IoU)\n",
        "        if predicted_boxes and ground_truth_boxes:\n",
        "            best_IoU = 0.0\n",
        "            best_confidence = 0.0\n",
        "            # Compare each predicted box with the ground truth boxes to find the best matching IoU\n",
        "            for pred_box, conf in zip(predicted_boxes, confs):\n",
        "                for b in ground_truth_boxes:\n",
        "                    # Calculate the IoU between the predicted and ground truth boxes\n",
        "                    IoU = cal_bb_IoU(pred_box, b)\n",
        "                    # Keep track of the best IoU and associated conf\n",
        "                    if IoU > best_IoU:\n",
        "                        best_IoU = IoU\n",
        "                        best_confidence = conf\n",
        "            # Add the evaluation results for the current image to the list\n",
        "            eva_results.append({\n",
        "                'image_name': img_file,\n",
        "                'confidence value': best_confidence,\n",
        "                'IoU value': best_IoU\n",
        "            })\n",
        "\n",
        "        # Case: There are predictions but no ground truth (false positive case)\n",
        "        elif predicted_boxes and not ground_truth_boxes:\n",
        "            eva_results.append({\n",
        "                'image_name': img_file,\n",
        "                'confidence value': confs[0],  # Use the first confidence value\n",
        "                'IoU value': 0.0  # No ground truth to calculate IoU\n",
        "            })\n",
        "\n",
        "        # Case: No predictions or incorrect predictions (false negative or wrong predictions)\n",
        "        else:\n",
        "            eva_results.append({\n",
        "                'image_name': img_file,\n",
        "                'confidence value': 0.0,\n",
        "                'IoU value': 0.0\n",
        "            })\n",
        "\n",
        "        # If an output directory is specified and predictions exist, save the output images\n",
        "        if output_img_dir and predicted_boxes:\n",
        "            os.makedirs(output_img_dir, exist_ok=True)\n",
        "\n",
        "    # Convert the collected evaluation results into a DataFrame for easy analysis\n",
        "    df = pd.DataFrame(eva_results)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "s-IZoMe4u_0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eva_image = '/content/drive/MyDrive/Colab Notebooks/dataset/eva_img' # evaluation images path\n",
        "\n",
        " # Create the output folder if it doesn't exist\n",
        "if not os.path.exists(eva_image):\n",
        "  os.makedirs(eva_image)\n",
        "\n",
        "df_results = model_evaluation(model, selected_test_img_dir , selected_test_labels_dir , eva_image)\n",
        "df_results.to_csv(f'{eva_image}/evaluation_results.csv')\n",
        "print(\"The CSV file is saved to: \", f'{eva_image}/evaluation_results.csv')\n"
      ],
      "metadata": {
        "id": "MBE5G0d_zRZA",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708f6f59-6243-4931-c853-a9b8b016921f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating.....: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 28.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CSV file is saved to:  /content/drive/MyDrive/Colab Notebooks/dataset/eva_img/evaluation_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iteratively train and test the model with a new\n",
        "set of 400 training and 40 test images**"
      ],
      "metadata": {
        "id": "zU6aqCQ61C0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "acc = 0.9 # target accuracy for new training and test images\n",
        "iteration = 1\n",
        "\n",
        "random.seed(42)\n",
        "new_selected_train = set()\n",
        "new_selected_test = set()\n",
        "\n",
        "# Specify model save directory in Google Drive\n",
        "model_save_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/model'\n",
        "\n",
        " # Create the output folder if it doesn't exist\n",
        "if not os.path.exists(model_save_dir):\n",
        "     os.makedirs(model_save_dir)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XRvX17aTtD46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    print(f\"----Iterating...... {iteration}----\")\n",
        "\n",
        "    new_selected_train_img = image_selecting(train_img, selected_train_img_dir, 400, new_selected_train)\n",
        "    anno_copy(train_img, selected_train_labels_dir, train_labels)\n",
        "    new_selected_test_img = image_selecting(test_img, selected_test_img_dir, 40, new_selected_test)\n",
        "    anno_copy(test_img, selected_test_labels_dir, test_labels)\n",
        "\n",
        "    # Define YAML file for the current iteration\n",
        "    yaml_file = f'/content/drive/MyDrive/Colab Notebooks/dataset/graffiti_{iteration}.yaml'\n",
        "\n",
        "   # Prepare data to be written into the YAML file\n",
        "    yaml_data = {\n",
        "     'train': os.path.abspath(selected_train_img_dir),\n",
        "     'val': os.path.abspath(selected_test_img_dir),\n",
        "     'nc': 1,  # Number of classes\n",
        "     'names': ['Graffiti']  # Class names\n",
        "   }\n",
        "\n",
        "# Write the data into the YAML file\n",
        "    with open(yaml_file, 'w') as file:\n",
        "      yaml.dump(yaml_data, file, indent=2)\n",
        "\n",
        "    print(\"--------Train model part----------\")\n",
        "\n",
        "    train_model = model.train(\n",
        "            data = yaml_file,\n",
        "            epochs = 4,\n",
        "            imgsz = 640,\n",
        "            batch = 16,\n",
        "            name = f'graffiti_detection_iter_{iteration}',\n",
        "    )\n",
        "\n",
        "    temporary_path = f'runs/detect/graffiti_detection_iter_{iteration}'\n",
        "\n",
        "    path_for_best_pt = os.path.join(temporary_path, 'weights', 'best.pt')\n",
        "\n",
        "    best_pt_iteration_path = os.path.join(model_save_dir, f'graffiti_detection_iter_{iteration}.pt')\n",
        "    os.makedirs(os.path.dirname(best_pt_iteration_path), exist_ok=True)\n",
        "\n",
        "    shutil.copy(path_for_best_pt, best_pt_iteration_path)\n",
        "    print(f\"The best.pt is saved for iteration {iteration} at {best_pt_iteration_path}\")\n",
        "\n",
        "    if not os.path.exists(path_for_best_pt):\n",
        "        raise FileNotFoundError(f\"The best model is not found at {path_for_best_pt}\")\n",
        "\n",
        "     # Load the best.pt of the current iteration for the next iteration\n",
        "    model = YOLO(best_pt_iteration_path)\n",
        "\n",
        "    df_results = model_evaluation(model, selected_test_img_dir, selected_test_labels_dir, eva_image)\n",
        "    df_results.to_csv(f'{eva_image}/eva_results_iter_{iteration}.csv')\n",
        "\n",
        "    best_result = f'{eva_image}/eval_{iteration}'\n",
        "    os.makedirs(best_result, exist_ok=True)\n",
        "\n",
        "    # Identify the two images with the highest IoU values\n",
        "    best_two_results = df_results.nlargest(2, 'confidence value')\n",
        "\n",
        "    # Save the images with the predicted bounding boxes to the designated folder\n",
        "    for idx, row in best_two_results.iterrows():\n",
        "        image_name = row['image_name']\n",
        "        image_path = os.path.join(selected_test_img_dir, image_name)\n",
        "\n",
        "        # Make predictions using the model\n",
        "        predictions = model.predict(image_path, conf = 0.25)\n",
        "\n",
        "        # Save the annotated image to the best result folder\n",
        "        annotated_frame = predictions[0].plot()\n",
        "\n",
        "        # Save the image with bounding boxes\n",
        "        output_path = os.path.join(best_result, image_name)\n",
        "        cv2.imwrite(output_path, annotated_frame)\n",
        "\n",
        "    # Compute the accuracy for images with IoU above the threshold of 0.8\n",
        "    accuracy = (df_results['IoU value'] >= 0.8).mean()\n",
        "    print(f\"Iteration {iteration} with the accuracy (IoU >= 0.8): {accuracy * 100:.2f}%\")\n",
        "\n",
        "    iteration += 1\n",
        "    # Verify if the performance target is met or if all images have been processed\n",
        "    if accuracy >= acc or (len(new_selected_train) == files_count(train_img) or len(new_selected_test) == files_count(test_img)):\n",
        "        print(f\"Requirement satisfied.\")\n",
        "        break\n",
        "\n",
        "df_results.to_csv(f'{eva_image}/eva_results.csv', index=False)\n",
        "print(\"Complete the iterative training and test\")\n"
      ],
      "metadata": {
        "id": "IheTeUSC2X7s",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f351e11c-a624-413d-ac18-b80ca6b063eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----Iterating...... 1----\n",
            "--------Train model part----------\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/Colab Notebooks/dataset/graffiti_1.yaml, epochs=4, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=graffiti_detection_iter_1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/graffiti_detection_iter_1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 94/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/graffiti_detection_iter_1', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 70.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/graffiti_detection_iter_1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/graffiti_detection_iter_1\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/4      2.35G      2.537      2.926      2.226         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:10<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         98      0.235      0.112     0.0789     0.0416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/4      2.24G      1.914      2.337      1.699         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         98      0.423      0.245      0.229      0.127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/4      2.28G      1.743      2.141      1.566         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         98      0.393      0.367      0.318      0.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/4      2.23G       1.64      2.015       1.49         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         98      0.598      0.357      0.401      0.234\n",
            "\n",
            "4 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from runs/detect/graffiti_detection_iter_1/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/graffiti_detection_iter_1/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/graffiti_detection_iter_1/weights/best.pt...\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         98      0.598      0.357      0.401      0.235\n",
            "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/graffiti_detection_iter_1\u001b[0m\n",
            "The best.pt is saved for iteration 1 at /content/drive/MyDrive/Colab Notebooks/dataset/model/graffiti_detection_iter_1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating.....: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 24.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 with the accuracy (IoU >= 0.8): 37.50%\n",
            "----Iterating...... 2----\n",
            "--------Train model part----------\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Colab Notebooks/dataset/model/graffiti_detection_iter_1.pt, data=/content/drive/MyDrive/Colab Notebooks/dataset/graffiti_2.yaml, epochs=4, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=graffiti_detection_iter_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/graffiti_detection_iter_2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 94/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/graffiti_detection_iter_2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train... 400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:02<00:00, 160.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 74.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test.cache\n",
            "Plotting labels to runs/detect/graffiti_detection_iter_2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/graffiti_detection_iter_2\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/4      2.35G      1.818      2.217      1.584         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:11<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         72      0.401      0.472      0.404      0.239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/4      2.24G      1.729      2.056      1.516         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:10<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         72      0.579      0.375      0.409      0.235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/4      2.25G      1.673      1.992      1.461         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:10<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         72      0.498      0.444      0.454      0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/4      2.28G      1.624      1.937      1.478         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         72      0.542      0.486      0.483      0.294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from runs/detect/graffiti_detection_iter_2/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/graffiti_detection_iter_2/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/graffiti_detection_iter_2/weights/best.pt...\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         72       0.54      0.486      0.483      0.294\n",
            "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/graffiti_detection_iter_2\u001b[0m\n",
            "The best.pt is saved for iteration 2 at /content/drive/MyDrive/Colab Notebooks/dataset/model/graffiti_detection_iter_2.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating.....: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 35.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2 with the accuracy (IoU >= 0.8): 35.00%\n",
            "----Iterating...... 3----\n",
            "--------Train model part----------\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Colab Notebooks/dataset/model/graffiti_detection_iter_2.pt, data=/content/drive/MyDrive/Colab Notebooks/dataset/graffiti_3.yaml, epochs=4, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=graffiti_detection_iter_3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/graffiti_detection_iter_3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 94/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/graffiti_detection_iter_3', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train... 13 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 171.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 45.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/dataset/labels/selected_test.cache\n",
            "Plotting labels to runs/detect/graffiti_detection_iter_3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/graffiti_detection_iter_3\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/4      1.86G      1.757      1.993       1.42         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         73      0.531      0.325      0.323      0.172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/4      1.88G      1.565      1.844      1.508         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         73      0.535      0.342      0.353      0.197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/4      1.86G       1.84      2.071      1.416         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         73      0.531      0.342      0.375      0.211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/4      1.87G       1.76      1.897      1.463         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         73      0.568       0.37      0.398      0.226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4 epochs completed in 0.004 hours.\n",
            "Optimizer stripped from runs/detect/graffiti_detection_iter_3/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/graffiti_detection_iter_3/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/graffiti_detection_iter_3/weights/best.pt...\n",
            "Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         73      0.567       0.37      0.397      0.226\n",
            "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/graffiti_detection_iter_3\u001b[0m\n",
            "The best.pt is saved for iteration 3 at /content/drive/MyDrive/Colab Notebooks/dataset/model/graffiti_detection_iter_3.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating.....: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 25.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 3 with the accuracy (IoU >= 0.8): 17.50%\n",
            "Requirement satisfied.\n",
            "Complete the iterative training and test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use your final model to detect graffiti in real-time video data.**"
      ],
      "metadata": {
        "id": "lO-gbZ2WBQ5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the final model for detection\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/dataset/model/graffiti_detection_iter_3.pt'\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "f71uQ6UMAxpe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path where i store 5 videos on Google Drive\n",
        "video_directory = '/content/drive/MyDrive/Colab Notebooks/dataset/videos'"
      ],
      "metadata": {
        "id": "4IF-T1Ecep55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all the .mp4 video files in the directory\n",
        "video_files = [f for f in os.listdir(video_directory) if f.endswith('.mp4')]"
      ],
      "metadata": {
        "id": "-iU1PLxQMETA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process and detect graffiti in video frames\n",
        "def process_video(video_path, model):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Set the output video parameters (same resolution as the input)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    output_path = video_path.replace('.mp4', '_processed.avi')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Make predictions on the current frame\n",
        "        results = model.predict(frame, conf=0.25)  # Adjust confidence threshold if necessary\n",
        "\n",
        "        # Plot the results on the frame (bounding boxes)\n",
        "        annotated_frame = results[0].plot()  # Add bounding boxes to the frame\n",
        "\n",
        "        # Write the processed frame to the output video\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "        # To display the frame in Colab\n",
        "        from matplotlib import pyplot as plt\n",
        "        plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return output_path  # Return path to processed video"
      ],
      "metadata": {
        "id": "L3HU15rmU8Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to hold the download links for processed videos\n",
        "download_links = []\n",
        "\n",
        "# Process all video files in the directory\n",
        "for video_file in video_files:\n",
        "    video_path = os.path.join(video_directory, video_file)\n",
        "    print(f'Processing video: {video_file}')\n",
        "    output_video = process_video(video_path, model)\n",
        "    print(f'Processed video saved as: {output_video}')\n",
        "\n",
        "    # Add the output video to the download links list\n",
        "    download_links.append(output_video)\n",
        "\n",
        "# Provide download links for all processed videos\n",
        "from google.colab import files\n",
        "for output_video in download_links:\n",
        "    files.download(output_video)  # This will prompt the download of each processed video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "4pC1M0s_gBMg",
        "outputId": "65955140-2f97-4011-cbaa-554f976c8391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}